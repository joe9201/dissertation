{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f300957e-c30a-4a5d-880c-5bd2e525a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from causallib.estimation import IPW\n",
    "from causalvis import CohortEvaluator, TreatmentEffectExplorer\n",
    "from data_preparation import apply_variable_mapping, student_variable_mapping, load_and_prepare_adult_data, load_and_prepare_student_data\n",
    "from matching import perform_matching\n",
    "from dag_utils import load_dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c35da220-5cb2-4642-b6d0-b3c62a6574de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_types(data):\n",
    "    \"\"\" Convert numpy data types to native Python types for JSON serialization. \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        return {k: convert_types(v) for k, v in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [convert_types(i) for i in data]\n",
    "    elif isinstance(data, (np.int32, np.int64)):\n",
    "        return int(data)\n",
    "    elif isinstance(data, (np.float32, np.float64)):\n",
    "        return float(data)\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2a4beab-5cbc-4841-8cd9-df5af65f7dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Confounds:  ['Medu', 'health', 'internet_yes', 'failures', 'famsup_yes']\n",
      "Filtered Prognostics:  ['higher_yes', 'paid_yes', 'schoolsup', 'studytime', 'Pstatus']\n"
     ]
    }
   ],
   "source": [
    "dataset = 'student'  # Change to 'adult', 'student', 'adult_small', or 'student_small'\n",
    "\n",
    "# Load and prepare data based on the dataset selection\n",
    "if dataset == 'adult':\n",
    "    data_file = 'data/adult_cleaned.csv'\n",
    "    dag_file = 'adult_true_confounds.json'\n",
    "    df_encoded, labels, data = load_and_prepare_adult_data(data_file)\n",
    "elif dataset == 'student':\n",
    "    data_file = 'data/student-por_raw.csv'\n",
    "    dag_file = 'student_true_confounds.json'\n",
    "    df_encoded, labels, data = load_and_prepare_student_data(data_file)\n",
    "elif dataset == 'adult_small':\n",
    "    data_file = 'data/smaller_adult_dataset.csv'\n",
    "    dag_file = 'small_adult_true_confounds.json'\n",
    "    df_encoded, labels, data = load_and_prepare_adult_data(data_file)\n",
    "elif dataset == 'student_small':\n",
    "    data_file = 'data/smaller_student_dataset.csv'\n",
    "    dag_file = 'small_student_true_confounds.json'\n",
    "    df_encoded, labels, data = load_and_prepare_student_data(data_file)\n",
    "\n",
    "# Apply variable mapping if the student dataset is selected\n",
    "if dataset == 'student' or dataset == 'student_small':\n",
    "    confounds = apply_variable_mapping(confounds, student_variable_mapping)\n",
    "    prognostics = apply_variable_mapping(prognostics, student_variable_mapping)\n",
    "\n",
    "# Ensure boolean columns are explicitly converted to integers if using student dataset\n",
    "if dataset == 'student' or dataset == 'student_small':\n",
    "    boolean_columns = ['internet_yes', 'higher_yes', 'famsup_yes', 'paid_yes']\n",
    "    for col in boolean_columns:\n",
    "        if col in df_encoded.columns:\n",
    "            df_encoded[col] = df_encoded[col].astype(int)\n",
    "\n",
    "# Filter confounds and prognostics to include only those present in the dataset\n",
    "confounds = [var for var in confounds if var in labels]\n",
    "prognostics = [var for var in prognostics if var in labels]\n",
    "\n",
    "if not confounds:\n",
    "    print(\"Warning: No confounds are present in the dataset. Proceed with caution.\")\n",
    "if not prognostics:\n",
    "    print(\"Warning: No prognostics are present in the dataset. Proceed with caution.\")\n",
    "\n",
    "print(\"Filtered Confounds: \", confounds)\n",
    "print(\"Filtered Prognostics: \", prognostics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d081a10c-5d83-40c8-92c1-3ea1e7075e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before matching - df_encoded shape: (410, 13)\n",
      "Covariates:  ['Medu', 'health', 'internet_yes', 'failures', 'famsup_yes', 'higher_yes', 'paid_yes', 'schoolsup', 'studytime', 'Pstatus']\n",
      "X shape:  (410, 10)\n",
      "X types:  Medu            float64\n",
      "health            int64\n",
      "internet_yes       bool\n",
      "failures          int64\n",
      "famsup_yes         bool\n",
      "higher_yes         bool\n",
      "paid_yes           bool\n",
      "schoolsup         int64\n",
      "studytime         int64\n",
      "Pstatus           int64\n",
      "dtype: object\n",
      "a shape:  (410,)\n",
      "a types:  int32\n",
      "y shape:  (410,)\n",
      "y types:  float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adams\\OneDrive\\Desktop\\causal test\\causalvis_env\\lib\\site-packages\\causallib\\estimation\\matching.py:475: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  X_at_a = X[self.treatments_ == a].copy()\n"
     ]
    },
    {
     "ename": "IndexingError",
     "evalue": "Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Perform matching\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBefore matching - df_encoded shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_encoded\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m adjustedCohort, unadjustedCohort \u001b[38;5;241m=\u001b[39m \u001b[43mperform_matching\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprognostics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreatment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter matching - adjustedCohort length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(adjustedCohort)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, unadjustedCohort length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(unadjustedCohort)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\causal test\\matching.py:46\u001b[0m, in \u001b[0;36mperform_matching\u001b[1;34m(df_encoded, confounds, prognostics, treatment, outcome)\u001b[0m\n\u001b[0;32m     44\u001b[0m unadjustedCohort \u001b[38;5;241m=\u001b[39m formatData(X, a, y, propMatrix)\n\u001b[0;32m     45\u001b[0m matcher \u001b[38;5;241m=\u001b[39m MatchingTransformer(with_replacement\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, caliper\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m \u001b[43mmatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m Xm, am, ym \u001b[38;5;241m=\u001b[39m matcher\u001b[38;5;241m.\u001b[39mtransform(X, a, y)\n\u001b[0;32m     48\u001b[0m propMatrixm \u001b[38;5;241m=\u001b[39m ipw\u001b[38;5;241m.\u001b[39mcompute_propensity_matrix(Xm, am)\u001b[38;5;241m.\u001b[39mto_dict(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\causal test\\causalvis_env\\lib\\site-packages\\causallib\\preprocessing\\transformers.py:371\u001b[0m, in \u001b[0;36mMatchingTransformer.fit\u001b[1;34m(self, X, a, y)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, a, y):\n\u001b[0;32m    355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit data to transform\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \n\u001b[0;32m    357\u001b[0m \u001b[38;5;124;03m    This function loads the data for matching and must be called before\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03m        self (MatchingTransformer) : Fitted object\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 371\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatching\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\causal test\\causalvis_env\\lib\\site-packages\\causallib\\estimation\\matching.py:158\u001b[0m, in \u001b[0;36mMatching.fit\u001b[1;34m(self, X, a, y, sample_weight)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropensity_transform\u001b[38;5;241m.\u001b[39mfit(X, a)\n\u001b[0;32m    156\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropensity_transform\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconditioned_covariance_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_covariance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtreatment_knns_ \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtreatments_\u001b[38;5;241m.\u001b[39munique():\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\causal test\\causalvis_env\\lib\\site-packages\\causallib\\estimation\\matching.py:475\u001b[0m, in \u001b[0;36mMatching._calculate_covariance\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    473\u001b[0m V_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtreatments_\u001b[38;5;241m.\u001b[39munique():\n\u001b[1;32m--> 475\u001b[0m     X_at_a \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtreatments_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    476\u001b[0m     current_V \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariance_conditioner\u001b[38;5;241m.\u001b[39mfit(X_at_a)\u001b[38;5;241m.\u001b[39mcovariance_\n\u001b[0;32m    477\u001b[0m     V_list\u001b[38;5;241m.\u001b[39mappend(current_V)\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\causal test\\causalvis_env\\lib\\site-packages\\pandas\\core\\frame.py:4093\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   4092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 4093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4095\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   4096\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   4097\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\causal test\\causalvis_env\\lib\\site-packages\\pandas\\core\\frame.py:4149\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   4144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mItem wrong length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(key)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4145\u001b[0m     )\n\u001b[0;32m   4147\u001b[0m \u001b[38;5;66;03m# check_bool_indexer will throw exception if Series key cannot\u001b[39;00m\n\u001b[0;32m   4148\u001b[0m \u001b[38;5;66;03m# be reindexed to match DataFrame rows\u001b[39;00m\n\u001b[1;32m-> 4149\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_bool_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m   4152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\causal test\\causalvis_env\\lib\\site-packages\\pandas\\core\\indexing.py:2662\u001b[0m, in \u001b[0;36mcheck_bool_indexer\u001b[1;34m(index, key)\u001b[0m\n\u001b[0;32m   2660\u001b[0m indexer \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_indexer_for(index)\n\u001b[0;32m   2661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01min\u001b[39;00m indexer:\n\u001b[1;32m-> 2662\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\n\u001b[0;32m   2663\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnalignable boolean Series provided as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2664\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexer (index of the boolean Series and of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2665\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe indexed object do not match).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2666\u001b[0m     )\n\u001b[0;32m   2668\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   2670\u001b[0m \u001b[38;5;66;03m# fall through for boolean\u001b[39;00m\n",
      "\u001b[1;31mIndexingError\u001b[0m: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match)."
     ]
    }
   ],
   "source": [
    "if dataset == 'adult' or dataset == 'adult_small':\n",
    "    treatment = 'hours.per.week'\n",
    "    outcome = 'income'\n",
    "elif dataset == 'student' or dataset == 'student_small':\n",
    "    treatment = 'absences'\n",
    "    outcome = 'G_avg'\n",
    "else:\n",
    "    raise ValueError(\"Unknown dataset specified\")\n",
    "\n",
    "# Perform matching\n",
    "print(f\"Before matching - df_encoded shape: {df_encoded.shape}\")\n",
    "adjustedCohort, unadjustedCohort = perform_matching(df_encoded, confounds, prognostics, treatment, outcome)\n",
    "print(f\"After matching - adjustedCohort length: {len(adjustedCohort)}, unadjustedCohort length: {len(unadjustedCohort)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "888eae3d-d6d2-4b57-92a7-5374746b62b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjustedCohort = convert_types(adjustedCohort)\n",
    "unadjustedCohort = convert_types(unadjustedCohort)\n",
    "\n",
    "# Save cohorts for visualization\n",
    "base_name = os.path.splitext(os.path.basename(dag_file))[0]\n",
    "adjusted_file_name = f'adjustedCohort_{base_name}.json'\n",
    "unadjusted_file_name = f'unadjustedCohort_{base_name}.json'\n",
    "\n",
    "with open(adjusted_file_name, 'w') as f:\n",
    "    json.dump(adjustedCohort, f, indent=4)\n",
    "with open(unadjusted_file_name, 'w') as f:\n",
    "    json.dump(unadjustedCohort, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d337ff0-d5ee-4e31-b450-dfc168d0d1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6beede67694493b8ea9d2e7e7aefda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CohortEvaluator(component='CohortEvaluator', props={'unadjustedCohort': [{'race': 1, 'age': 82, 'native.countr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cohort_evaluator = CohortEvaluator(unadjustedCohort=unadjustedCohort)\n",
    "display(cohort_evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21e92839-4b89-46b7-a535-15d20b888221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Treatment Effect (ATE): 0.12156228163190821\n"
     ]
    }
   ],
   "source": [
    "X = df_encoded[confounds + prognostics]\n",
    "a = df_encoded[treatment] >= df_encoded[treatment].median()\n",
    "a = a.astype(int)\n",
    "y = df_encoded[outcome]\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "ipw = IPW(lr)\n",
    "ipw.fit(X, a)\n",
    "\n",
    "# Calculate the ATE\n",
    "outcomes = ipw.estimate_population_outcome(X, a, y)\n",
    "ate = outcomes[1] - outcomes[0]\n",
    "print(f\"Average Treatment Effect (ATE): {ate}\")\n",
    "\n",
    "# Convert data types\n",
    "adjustedCohort = convert_types(adjustedCohort)\n",
    "unadjustedCohort = convert_types(unadjustedCohort)\n",
    "\n",
    "# Save cohorts for visualization\n",
    "base_name = os.path.splitext(os.path.basename(dag_file))[0]\n",
    "adjusted_file_name = f'adjustedCohort_{base_name}.json'\n",
    "unadjusted_file_name = f'unadjustedCohort_{base_name}.json'\n",
    "\n",
    "with open(adjusted_file_name, 'w') as f:\n",
    "    json.dump(adjustedCohort, f, indent=4)\n",
    "with open(unadjusted_file_name, 'w') as f:\n",
    "    json.dump(unadjustedCohort, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c103f30-13a3-4b9e-9e6c-778faf233b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
